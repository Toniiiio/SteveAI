output$curl <- renderPrint(global$items)
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
server = function(input, output) {
global <- reactiveValues(curl_output = NULL, error_items = error_items)
output$items <- renderUI({
print(length(global$error_items))
selectInput(
inputId = "error_item",
label = "Error item:",
choices = global$error_items,
selected = global$error_items[1]
)
})
observeEvent(input$finish_item, {
print(input$finish_item)
print(input$error_item)
print(length(unlist(global$error_items)))
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
global$error_items <- setdiff(global$error_items, input$error_item)
print(length(unlist(global$error_items)))
})
observeEvent(input$add_nojob_id, {
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$error_item, {
req(input$error_item)
print(input$error_item)
scrape_url <- rvestScraper[[input$error_item]]$url
global$doc <- tryCatch(expr = scrape_url %>%
httr::GET() %>%
httr::content(type = "text"),
error = function(e) NULL
)
})
observeEvent(input$get_xpath, {
print(input$target_text)
print(global$doc)
txt <- getXPathByText(doc = global$doc, text = input$target_text)
print(txt)
output$xpath <- renderUI({
textInput(inputId = "xpath", label = "xpath:", value = txt %>% toString)
})
})
observeEvent(input$use_xpath, {
global$items <- global$doc %>%
xml2::read_html() %>%
rvest::html_nodes(xpath = input$xpath) %>%
rvest::html_text()
print(global$items)
})
output$curl <- renderPrint(global$items)
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
server = function(input, output) {
global <- reactiveValues(curl_output = NULL, error_items = error_items)
output$items <- renderUI({
print(length(global$error_items))
selectInput(
inputId = "error_item",
label = "Error item:",
choices = global$error_items,
selected = global$error_items[1]
)
})
observeEvent(input$finish_item, {
print(input$finish_item)
print(input$error_item)
print(length(unlist(global$error_items)))
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
global$error_items <- setdiff(global$error_items, input$error_item)
print(length(unlist(global$error_items)))
})
observeEvent(input$add_nojob_id, {
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$error_item, {
req(input$error_item)
print(input$error_item)
scrape_url <- rvestScraper[[input$error_item]]$url
global$doc <- tryCatch(expr = scrape_url %>%
httr::GET() %>%
httr::content(type = "text"),
error = function(e) NULL
)
})
observeEvent(input$get_xpath, {
print(input$target_text)
print(global$doc)
txt <- getXPathByText(doc = global$doc, text = input$target_text)
print(txt)
output$xpath <- renderUI({
textInput(inputId = "xpath", label = "xpath:", value = txt %>% toString)
})
})
observeEvent(input$use_xpath, {
global$items <- global$doc %>%
xml2::read_html() %>%
rvest::html_nodes(xpath = input$xpath) %>%
rvest::html_text()
print(global$items)
})
output$curl <- renderPrint(global$items)
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
server = function(input, output) {
global <- reactiveValues(curl_output = NULL, error_items = error_items)
output$items <- renderUI({
print(length(global$error_items))
selectInput(
inputId = "error_item",
label = "Error item:",
choices = global$error_items,
selected = global$error_items[1]
)
})
observeEvent(input$finish_item, {
print(input$finish_item)
print(input$error_item)
print(length(unlist(global$error_items)))
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
global$error_items <- setdiff(global$error_items, input$error_item)
print(length(unlist(global$error_items)))
})
observeEvent(input$add_nojob_id, {
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$error_item, {
req(input$error_item)
print(input$error_item)
scrape_url <- rvestScraper[[input$error_item]]$url
global$doc <- tryCatch(expr = scrape_url %>%
httr::GET() %>%
httr::content(type = "text"),
error = function(e) NULL
)
})
observeEvent(input$get_xpath, {
print(input$target_text)
print(global$doc)
txt <- getXPathByText(doc = global$doc, text = input$target_text)
print(txt)
output$xpath <- renderUI({
textInput(inputId = "xpath", label = "xpath:", value = txt %>% toString)
})
})
observeEvent(input$use_xpath, {
global$items <- global$doc %>%
xml2::read_html() %>%
rvest::html_nodes(xpath = input$xpath) %>%
rvest::html_text()
print(global$items)
global$xpath_output <- "global$items"
})
output$curl <- renderPrint(global$xpath_output)
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
server = function(input, output) {
global <- reactiveValues(curl_output = NULL, error_items = error_items, xpath_output = NULL)
output$items <- renderUI({
print(length(global$error_items))
selectInput(
inputId = "error_item",
label = "Error item:",
choices = global$error_items,
selected = global$error_items[1]
)
})
observeEvent(input$finish_item, {
print(input$finish_item)
print(input$error_item)
print(length(unlist(global$error_items)))
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
global$error_items <- setdiff(global$error_items, input$error_item)
print(length(unlist(global$error_items)))
})
observeEvent(input$add_nojob_id, {
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$error_item, {
req(input$error_item)
print(input$error_item)
scrape_url <- rvestScraper[[input$error_item]]$url
global$doc <- tryCatch(expr = scrape_url %>%
httr::GET() %>%
httr::content(type = "text"),
error = function(e) NULL
)
})
observeEvent(input$get_xpath, {
print(input$target_text)
print(global$doc)
txt <- getXPathByText(doc = global$doc, text = input$target_text)
print(txt)
output$xpath <- renderUI({
textInput(inputId = "xpath", label = "xpath:", value = txt %>% toString)
})
})
observeEvent(input$use_xpath, {
global$items <- global$doc %>%
xml2::read_html() %>%
rvest::html_nodes(xpath = input$xpath) %>%
rvest::html_text()
print(global$items)
global$xpath_output <- "global$items"
output$curl <- renderPrint(global$xpath_output)
})
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
server = function(input, output) {
global <- reactiveValues(curl_output = NULL, error_items = error_items, xpath_output = NULL)
output$items <- renderUI({
print(length(global$error_items))
selectInput(
inputId = "error_item",
label = "Error item:",
choices = global$error_items,
selected = global$error_items[1]
)
})
observeEvent(input$finish_item, {
print(input$finish_item)
print(input$error_item)
print(length(unlist(global$error_items)))
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
global$error_items <- setdiff(global$error_items, input$error_item)
print(length(unlist(global$error_items)))
})
observeEvent(input$add_nojob_id, {
rvestScraper[[input$error_item]]$no_job_id <- input$no_job_id
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$error_item, {
req(input$error_item)
print(input$error_item)
scrape_url <- rvestScraper[[input$error_item]]$url
global$doc <- tryCatch(expr = scrape_url %>%
httr::GET() %>%
httr::content(type = "text"),
error = function(e) NULL
)
})
observeEvent(input$get_xpath, {
print(input$target_text)
print(global$doc)
txt <- getXPathByText(doc = global$doc, text = input$target_text)
print(txt)
output$xpath <- renderUI({
textInput(inputId = "xpath", label = "xpath:", value = txt %>% toString)
})
})
observeEvent(input$use_xpath, {
global$items <- global$doc %>%
xml2::read_html() %>%
rvest::html_nodes(xpath = input$xpath) %>%
rvest::html_text()
print(global$items)
global$xpath_output <- global$items
output$curl <- renderPrint(global$xpath_output)
})
observeEvent(input$add_new_url, {
rvestScraper[[input$error_item]]$url <- input$new_url
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
})
observeEvent(input$curl, {
url <- rvestScraper[[input$error_item]]$url
global$curl_output <- system(command = glue::glue("curl {url}"), intern = TRUE)
})
output$curl <- renderPrint(global$curl_output)
observeEvent(input$domain, {
url <- rvestScraper[[input$error_item]]$url
domain <- urltools::domain(url)
global$domain_output <- httr::GET(url = domain)
})
output$curl <- renderPrint(global$domain_output)
observeEvent(input$remove, {
print(rvestScraper[[input$error_item]])
rvestScraper[[input$error_item]] <- NULL
save(rvestScraper, file = file.path(SteveAI_dir, "scraper_rvest.RData"))
### add: are you sure?
})
observeEvent(input$google_search, {
glue::glue("https://www.google.de/search?q={input$error_item}+jobs") %>%
browseURL()
})
observeEvent(input$open_scrape_url, {
rvestScraper[[input$error_item]]$url %>%
browseURL()
})
data <- reactive({
req(input$min_nodes)
log_data %<>% dplyr::filter(as.numeric(n_nodes) >= input$min_nodes | is.na(n_nodes))
log_data %<>% dplyr::filter(!is.na(missing_object) == input$obj_has_txt)
log_data
})
output$tbl_all = renderDT(
datatable(data(), filter = 'top'), options = list(lengthChange = FALSE)
)
output$tbl_single = renderDT(
datatable(data() %>% dplyr::filter(comp_name == input$error_item), filter = 'top'), options = list(lengthChange = FALSE)
)
}
shinyApp(ui, server)
