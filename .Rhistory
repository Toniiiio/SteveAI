}
links <- link_meta$links
all_docs <- link_meta$all_docs
html_texts <- link_meta$html_texts
matches <- link_meta$matches
all_links <- link_meta$all_links
counts <- link_meta$counts
parsed_links <- link_meta$parsed_links
link <- links$href[1]
id <- c(iter_nr, target_link) %>% paste(collapse = "-")
print(link)
# workaround until frames are supported
if(is.na(link)){
exclude <- links$href %in% link
links <- links[!exclude, ]
message("skipping NA (frame link)")
return()
}
#all_docs[[id]] %>% showHtmlPage()
if(use_selenium){
out <- get_doc_selenium(url = link, remDr)
all_docs[[id]] <- out$doc
domain <- out$domain
}else if(use_phantom){
out <- get_doc_phantom(url = link, ses = ses)
ses <- out$ses
domain <- out$domain
all_docs[[id]] <- out$doc
}else{
all_docs[[id]] <- tryCatch(
expr = link %>% xml2::read_html(),
error = function(e) ""
)
}
has_doc <- nchar(all_docs[[id]] %>% toString)
if(has_doc){
all_links[[id]] <- all_docs[[id]] %>%
html_nodes(xpath = "//a") %>%
{data.frame(href = html_attr(x = ., name = "href"), text = html_text(.))}
# %>%{ifelse(test = substring(text = ., first = 1, last = 1) == "/", yes = paste0("https://www.", urltools::domain(link), .), no = .)}
html_texts[[id]] <- tryCatch(htm2txt::htm2txt(as.character(all_docs[[id]])),
error = function(e){
message(e)
warning(e)
return("")
})
}else{
all_links[[id]] <- data.frame(href = character(), text = character())
message("No content")
warning("No content")
return(
list(
links = links[-1, ], all_docs = all_docs, all_links = all_links,
parsed_links = parsed_links,
html_texts = html_texts, matches = matches, counts = counts
)
)
}
doc <- all_docs[[id]]
if(!exists("job_titles")) job_titles <- ""
matches[[iter_nr]] <- target_indicator_count(job_titles = job_titles, doc = doc)
counts[iter_nr] <- unlist(matches[[iter_nr]]) %>% as.numeric() %>% sum
# "https://careers.danone.com/de-global/" %in% links$href
# "https://careers.danone.com/de-global/" %in% links2$href
# todo: cant find src in code - maybe have to use swith to frame but cant use it as new link then
iframe_links_raw <- doc %>%
html_nodes(xpath = "//iframe") %>%
html_attr("src")
if(length(iframe_links_raw)){
if(is.na(iframe_links_raw)){
iframe_links_raw <- character()
}
}
iframe_links <- data.frame(href = iframe_links_raw, text = rep("iframe", length(iframe_links_raw)))
parsed_links[iter_nr, ]$href <- target_link$href
parsed_links[iter_nr, ]$text <- target_link$text
links <- rbind(iframe_links, links, all_links[[id]]) %>%
filter_links(domain = domain, parsed_links = parsed_links)
links <- links[!duplicated(links$href), ]
links$href
links <- rbind(parsed_links, links)
head(links)
exclude <- links$href %in% parsed_links$href
head(exclude)
links <- links[!exclude, ] %>% sort_links()
# taleo careersection jobsearch
head(links$href)
links$href <- gsub(x = links$href, pattern = "www.www.", replacement = "www.", fixed = TRUE)
ses$getUrl()
ses <- start_phantom()
ses$getUrl()
remove.packages("webdriver")
remove.packages("webdriver")
install.packages("webdriver")
install.packages("webdriver")
install.packages("webdriver", type = "source")
pjs <- webdriver::run_phantomjs()
pjs
webdriver::Session$new(port = pjs$port)
library(rvest)
library(httr)
library(magrittr)
library(urltools)
# system(
#   paste0("sudo -kS docker rm -vf $(docker ps -a -q)"),
#   input = "vistarundle1!!!"
# )
# system(
#   paste0("sudo -S docker rmi -f $(docker images -a -q)"),
#   input = "vistarundle1!!!"
# )
source("R/is_job_offer_page.R")
source("R/handle_links.R")
source("R/link_checker.R")
load("data/comp_urls_indeed.RData")
load("data/job_page_candidates_indeed.RData")
urls <- unlist(comp_urls)
source("R/rvestFunctions.R")
w <- (sapply(indeed_results, typeof, USE.NAMES = FALSE) == "list") %>%
unname %>%
which
w
sd <- sapply(indeed_results, typeof)
xxx <- which(sd == "list")
nr <- xxx[1]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
pjs <<- webdriver::run_phantomjs()
ses <<- webdriver::Session$new(port = pjs$port)
out <- configure_xpath(xpath, doc, ses, url)
out
nr <- xxx[2]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches
xx$parsed_links$href
#xx$matches
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
#   xx <- indeed_results[[url]]
xx$counts
ses$go("https://www.charleston-karriere.de/stellenanzeigen")
ses$takeScreenshot()
nr <- xxx[3]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
xx$winner
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
ses$go("https://www.charleston-karriere.de/stellenanzeigen")
ses$takeScreenshot()
ses$go("https://www.charite.de/en/careers/stellenboerse")
ses$takeScreenshot()
xx$matches[[8]]
#   xx <- indeed_results[[url]]
xx$counts
has_add_indicators <- function(html_text){
indicators <- c("m/w/x", "m/f/d", "w/m/d", "m/w/d", "stelle anzeigen", "vollzeit", "vollzeit/teilzeit", "treffer pro seite", "junior", "senior", "Mitarbeiter/In", "Assistent*in", "Referent*in", "Stellenangebot", "Bewerbungsfrist")
indicator_match <- sapply(indicators,stringr::str_count, string = tolower(html_text))
indicator_match %>% sum
}
target_indicator_count <- function(job_titles, doc){
if(!nchar(doc[1])) return(FALSE)
html_text <- tryCatch(doc %>% as.character %>% htm2txt::htm2txt(),
error = function(e){
message(e)
warning(e)
return("")
})
indicators <- c("m/w/x", "m/f/d", "f/m/d", "w/m/d", "m/w/d", "m/w", "d/f/m", "stelle anzeigen", "vollzeit", "vollzeit/teilzeit", "treffer pro seite", "junior", "senior",
"Technical Designer", "CRM Manager", "HR Advisor", "Sales Representative", "Process Engineer", "Mitarbeiter/In", "Assistent*in", "Referent*in", "Stellenangebot", "Bewerbungsfrist")
add_indicators <- match_strings(target_strings = indicators, html_text = html_text)
indeed_jobs <- approx_match_strings(target_strings = job_titles, html_text = html_text)
apply_button <- has_apply_button(doc)
job_name_db <- matches_job_name_db(doc = doc, html_text = html_text, db_name = "rvest_scraper.db", target_table_job = "RVEST_SINGLE_JOBS")
list(
add_indicators = add_indicators,
indeed_jobs = indeed_jobs,
apply_button = apply_button,
job_name_db = job_name_db
)
}
nr <- xxx[4]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
nr <- xxx[5]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
nr <- xxx[6]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
nr <- xxx[7]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
nr <- xxx[8]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
nr <- xxx[9]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
doc %>% SteveAI::showHtmlPage()
xx$parsed_links$href[xx$winner]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
nr <- xxx[10]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
required_len <- 2
xx$parsed_links$href[xx$winner] %>% browseURL()
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out
nr <- xxx[11]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
nr <- xxx[12]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
nr <- xxx[12]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
nr <- xxx[13]
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
# 13
nr <- xxx[14]
xx <- indeed_results[[nr]]
xx <- indeed_results[[url]]
# 13
nr <- xxx[14]
nr
xx <- indeed_results[[nr]]
#   xx <- indeed_results[[url]]
xx$counts
#xx$matches[[8]]
xx$parsed_links$href
xx$parsed_links$href[xx$winner]
doc <- xx$doc %>% xml2::read_html()
doc %>% SteveAI::showHtmlPage()
target_text <- xx$matches[[xx$winner]] %>%
{.[names(.) != "apply_button"]} %>%
unname %>%
unlist(recursive = TRUE) %>%
{names(.)[which.max(as.numeric(.))]}
# target_text <- "junior"
target_text
#doc %>% SteveAI::showHtmlPage()
xpath <- SteveAI::getXPathByText(text = target_text, doc = doc, add_class = TRUE, exact = TRUE)
xpath
source("R/configure_xpath.R")
url <- xx$parsed_links$href[xx$winner]
out <- configure_xpath(xpath, doc, ses, url)
out
xx$parsed_links$href[xx$winner] %>% browseURL()
job_related_page_xp <- "//*[contains(text(), 'Find a job') or contains(text(), 'Search and apply') or contains(text(), 'Global Career Opportunities') or contains(text(), 'Search Jobs') or contains(text(), 'Search for jobs')]"
is_job_related <- ses$findElements(xpath = job_related_page_xp) %>% length
is_job_related
check_for_button <- function(links){
url_before <- ses$getUrl()
doc <- ses$findElement(xpath = "/*")
doc_len_before <- doc$getAttribute("innerHTML") %>% nchar
xp <- generate_button_xpath()
buttons <- ses$findElements(xpath = xp)
for(nr in seq(buttons)){
tryCatch(buttons[[nr]]$click(), error = function(e) message(e))
}
input_xpath <- "//input[@type = 'submit' or @value = 'Search Jobs' or @title = 'Search Jobs']"
inputs <- ses$findElements(xpath = input_xpath)
# todo: finish
button_xpath <- "//button[./parent::*//*[contains(text(), 'GO')]]"
buttons <- ses$findElements(xpath = input_xpath)
job_related_page_xp <- "//*[contains(text(), 'Find a job') or contains(text(), 'Search and apply') or contains(text(), 'Global Career Opportunities') or contains(text(), 'Search Jobs') or contains(text(), 'Search for jobs')]"
is_job_related <- ses$findElements(xpath = job_related_page_xp) %>% length
is_job_related
if(is_job_related){
for(nr in seq(inputs)){
# message("Found and trying a relevant input")
tryCatch(inputs[[nr]]$click(), error = function(e) message(e))
}
}
url_after <- ses$getUrl()
doc <- ses$findElement(xpath = "/*")
doc_len_after <- doc$getAttribute("innerHTML") %>% nchar
button_relevant <- url_after != url_before | doc_len_before != doc_len_after
if(button_relevant){
message("Found a relevant button")
links <- rbind(
data.frame(
href = url_after,
text = "Caused by SteveAI button click"
),
links
)
}
return(links)
}
pjs <<- webdriver::run_phantomjs()
ses <<- webdriver::Session$new(port = pjs$port)
grepl(pattern = "ckscience", x = urls)
grepl(pattern = "ckscience", x = urls) %>% which
#   xx <- indeed_results[[url]]
xx$counts
